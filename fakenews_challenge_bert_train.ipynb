{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-it_jeElOvXt"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets sentencepiece # to convert slow tokenizer to a fast one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu10J8nYR41Y",
        "outputId": "4a1e76aa-a995-4422-958c-15e1fcee4718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzCSos0fU79u",
        "outputId": "d562f1b2-9586-4a0d-fcf6-9300a324f40e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        }
      ],
      "source": [
        "import pytz, datetime\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"book\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "from transformers import get_linear_schedule_with_warmup #, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPPmoMUFi9EI"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "# https://wandb.ai/sauravmaheshkar/RSNA-MICCAI/reports/How-to-Set-Random-Seeds-in-PyTorch-and-Tensorflow--VmlldzoxMDA2MDQy\n",
        "def set_seed(seed: int = seed) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVCfGlSXgrjJ"
      },
      "outputs": [],
      "source": [
        "timezone = pytz.timezone(\"Europe/Rome\")\n",
        "utc_now = pytz.utc.localize(datetime.datetime.utcnow())\n",
        "pst_now = utc_now.astimezone(pytz.timezone(\"Europe/Rome\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9fxjBzNEY8U"
      },
      "source": [
        "###Setting Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuKSbk3aEJ05"
      },
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    0: 'true',\n",
        "    1: 'false'\n",
        "}\n",
        "\n",
        "config = {\n",
        "    'learning_rate': 5e-4 ,\n",
        "    'batch_size': 16,\n",
        "    'epochs': 5,\n",
        "    'dropout': 0.45,\n",
        "    'tokenizer_max_len': 128\n",
        "}\n",
        "\n",
        "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "#model_name = \"bert-base-uncased\"\n",
        "#model_name = \"microsoft/deberta-v2-xlarge-mnli\" # Doesn't fit in memory\n",
        "model_name = \"roberta-base\"\n",
        "#model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "\n",
        "GOLD_LABEL = 'label'\n",
        "TEXT = 'statement'\n",
        "path = \"/content/drive/MyDrive/Challenge NLP/models/\" + model_name.replace(\"/\", \"-\")\n",
        "n_labels = len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XqJ6GurD7gZ"
      },
      "source": [
        "###Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-FAE1zm-B"
      },
      "source": [
        "### Count tokens in statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pSA-YIiD7DZ",
        "outputId": "fe7ab141-71fc-4dcc-bb3d-f6969118f560"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-9af0a2acc1c5>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['label'].map({5: 3, 4: 0, 2: 3, 1: 3})\n",
            "<ipython-input-8-9af0a2acc1c5>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = ['true' if ele == 3 else 'false' for ele in df['label']]\n",
            "<ipython-input-8-9af0a2acc1c5>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['label'].map({5: 3, 4: 0, 2: 3, 1: 3})\n",
            "<ipython-input-8-9af0a2acc1c5>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = ['true' if ele == 3 else 'false' for ele in df['label']]\n",
            "<ipython-input-8-9af0a2acc1c5>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['label'].map({5: 3, 4: 0, 2: 3, 1: 3})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4523 553 553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-9af0a2acc1c5>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = ['true' if ele == 3 else 'false' for ele in df['label']]\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"liar\")\n",
        "\n",
        "#0 - False\n",
        "#1 - Half-true\n",
        "#2 - Mostly-true\n",
        "#3 - True\n",
        "#4 - Barely-true\n",
        "#5 - Pants-fire\n",
        "\n",
        "\n",
        "def preprocessing(df):\n",
        "\n",
        "    # Remove half-true\n",
        "    #df = df[df['label'].isin([0,2,3,4,5])]\n",
        "\n",
        "    # Remove half-true, mostly-true and barely-true\n",
        "    df = df[df['label'].isin([0,3,5])]\n",
        "\n",
        "\n",
        "    # Labels mapping:\n",
        "    # barely-true -> false\n",
        "    # pants-fire -> true\n",
        "    # mostly-true -> true\n",
        "    # half-true -> true\n",
        "    df['label'] = df['label'].map({5: 3, 4: 0, 2: 3, 1: 3})\n",
        "\n",
        "\n",
        "    # Text cleaning\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # To lower case\n",
        "        df.loc[index, \"statement\"] = df.loc[index, \"statement\"].lower()\n",
        "\n",
        "        # Remove punctuation\n",
        "        df.loc[index, \"statement\"] = re.sub(r'[^\\w\\s]', '', df.loc[index, \"statement\"])\n",
        "\n",
        "        # Remove stopwords\n",
        "        word_tokens = word_tokenize(df.loc[index, \"statement\"])\n",
        "        filtered_sentence = [w for w in word_tokens if w not in stop_words]\n",
        "        df.loc[index, \"statement\"] = ' '.join(filtered_sentence)\n",
        "\n",
        "        # Remove number assuming a fake or true news is not usually determined by the numbers presented\n",
        "        df.loc[index, \"statement\"] = re.sub(\"\\d+\", \" \", df.loc[index, \"statement\"])\n",
        "\n",
        "        # Remove extra spaces\n",
        "        df.loc[index, \"statement\"] = re.sub(\"\\s+\", \" \", df.loc[index, \"statement\"])\n",
        "\n",
        "\n",
        "\n",
        "    df['label'] = ['true' if ele == 3 else 'false' for ele in df['label']]\n",
        "    return df.dropna().reset_index()\n",
        "\n",
        "\n",
        "train = preprocessing(pd.DataFrame(data=dataset['train']))\n",
        "validation = preprocessing(pd.DataFrame(data=dataset['validation']))\n",
        "test = eval = preprocessing(pd.DataFrame(data=dataset['test']))\n",
        "\n",
        "print(len(train),len(eval),len(test)) #3681 461 461"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "Nn70UUL8myNQ",
        "outputId": "90e472c0-2dd3-4343-c340-50ad6bf34321"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ba14a7431ecd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"statement\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "train[\"statement\"].head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWZPwScKhw6q",
        "outputId": "cb6dc987-f28c-46c4-bdff-4149d29f1caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of false: 3681\n",
            "Number of true: 842\n",
            "Number of barely-true: 0\n",
            "Number of half-true: 0\n",
            "Number of mostly-true: 0\n",
            "Number of pants-fire: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of false: \" + str(train[train['label'] == \"false\"]['label'].count()))\n",
        "print(\"Number of true: \" + str(train[train['label'] == \"true\"]['label'].count()))\n",
        "print(\"Number of barely-true: \" + str(train[train['label'] == \"barely-true\"]['label'].count()))\n",
        "print(\"Number of half-true: \" + str(train[train['label'] == \"half-true\"]['label'].count()))\n",
        "print(\"Number of mostly-true: \" + str(train[train['label'] == \"mostly-true\"]['label'].count()))\n",
        "print(\"Number of pants-fire: \" + str(train[train['label'] == \"pants-fire\"]['label'].count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "A5a9FsMsX3RU",
        "outputId": "af99cc17-04e1-436a-d444-7d9179306eed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c1af87c-f6a7-4da8-be92-502e1ede613e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>job_title</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>barely_true_counts</th>\n",
              "      <th>false_counts</th>\n",
              "      <th>half_true_counts</th>\n",
              "      <th>mostly_true_counts</th>\n",
              "      <th>pants_on_fire_counts</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>5918</td>\n",
              "      <td>2621.json</td>\n",
              "      <td>true</td>\n",
              "      <td>rick scott doesnt ties lobbyist</td>\n",
              "      <td>candidates-biography</td>\n",
              "      <td>jennifer-carroll</td>\n",
              "      <td>Lieutenant governor</td>\n",
              "      <td>Florida</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>a speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c1af87c-f6a7-4da8-be92-502e1ede613e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c1af87c-f6a7-4da8-be92-502e1ede613e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c1af87c-f6a7-4da8-be92-502e1ede613e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      index         id label                        statement  \\\n",
              "2619   5918  2621.json  true  rick scott doesnt ties lobbyist   \n",
              "\n",
              "                   subject           speaker            job_title state_info  \\\n",
              "2619  candidates-biography  jennifer-carroll  Lieutenant governor    Florida   \n",
              "\n",
              "     party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
              "2619        republican                 0.0           1.0               0.0   \n",
              "\n",
              "      mostly_true_counts  pants_on_fire_counts   context  \n",
              "2619                 0.0                   1.0  a speech  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.sample(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnxHx89jTag0"
      },
      "outputs": [],
      "source": [
        "def mapping_dataset(dataset, mapping):\n",
        "    for index,row in dataset.iterrows():\n",
        "        number_label = [k for label in row[GOLD_LABEL].split(',') for k,v in mapping.items() if label.strip() == v]\n",
        "        dataset.loc[index, GOLD_LABEL] = str(number_label)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def one_hot_encoder(df):\n",
        "    one_hot_encoding = []\n",
        "    for i in tqdm(range(len(df)), desc='Loading:',disable=True):\n",
        "        temp = [0]*n_labels\n",
        "        label_indices = list(df.iloc[i][GOLD_LABEL][1:-1].split(', '))\n",
        "        for index in label_indices:\n",
        "            temp[int(index)] = 1\n",
        "        one_hot_encoding.append(temp)\n",
        "\n",
        "    return pd.DataFrame(one_hot_encoding)\n",
        "\n",
        "map_train = mapping_dataset(train, mapping)\n",
        "map_validation = mapping_dataset(validation, mapping)\n",
        "train = pd.concat([map_train, one_hot_encoder(map_train)], axis=1)\n",
        "valid = pd.concat([map_validation, one_hot_encoder(map_validation)], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "MNbwx98MZkZG",
        "outputId": "1cf45969-1f70-4e39-c675-1fa25abfbf54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e94236a6-96e6-4a1a-8089-ef300f7e00b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>job_title</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>barely_true_counts</th>\n",
              "      <th>false_counts</th>\n",
              "      <th>half_true_counts</th>\n",
              "      <th>mostly_true_counts</th>\n",
              "      <th>pants_on_fire_counts</th>\n",
              "      <th>context</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>1272</td>\n",
              "      <td>10087.json</td>\n",
              "      <td>[0]</td>\n",
              "      <td>federal tax refunds delayed october</td>\n",
              "      <td>taxes</td>\n",
              "      <td>chain-email</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>none</td>\n",
              "      <td>11.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>a chain email</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e94236a6-96e6-4a1a-8089-ef300f7e00b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e94236a6-96e6-4a1a-8089-ef300f7e00b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e94236a6-96e6-4a1a-8089-ef300f7e00b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     index          id label                              statement subject  \\\n",
              "569   1272  10087.json   [0]   federal tax refunds delayed october    taxes   \n",
              "\n",
              "         speaker job_title state_info party_affiliation  barely_true_counts  \\\n",
              "569  chain-email                                   none                11.0   \n",
              "\n",
              "     false_counts  half_true_counts  mostly_true_counts  pants_on_fire_counts  \\\n",
              "569          43.0               8.0                 5.0                 105.0   \n",
              "\n",
              "           context  0  1  \n",
              "569  a chain email  1  0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.sample(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7QOQJ6lEj1u"
      },
      "source": [
        "###Model Loading and Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKhD5sv_FTBN"
      },
      "source": [
        "####Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GDuf4wZFXMO"
      },
      "outputs": [],
      "source": [
        "class LiarDataset:\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        inputs = self.tokenizer.__call__(text,\n",
        "                                         None,\n",
        "                                         add_special_tokens=True,\n",
        "                                         max_length=self.max_len,\n",
        "                                         padding=\"max_length\",\n",
        "                                         truncation=True,\n",
        "                                         )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqgtXlRVFbFY"
      },
      "source": [
        "####Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kfABlfyFg8S"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, n_classes, do_prob, bert_model):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(do_prob)\n",
        "        self.out = nn.Linear(768, n_classes) # bert-base-uncased, roberta, distilbert\n",
        "        #self.out = nn.Linear(1536, config[\"batch_size\"]*config[\"tokenizer_max_len\"]) # microsoft/deberta-v2-xlarge-mnli\n",
        "\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        output_1 = self.bert(ids, attention_mask=mask)[\"pooler_output\"] # bert-base-uncased, roberta\n",
        "        #output_1 = self.bert(ids, attention_mask=mask)[\"last_hidden_state\"] # microsoft/deberta-v2-xlarge-mnli, distilbert\n",
        "        output_2 = self.dropout(output_1)\n",
        "        output = self.out(output_2)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5czYjH6dCt-o"
      },
      "outputs": [],
      "source": [
        "#bert_model = transformers.AutoModel.from_pretrained(model_name)\n",
        "#model = Classifier(n_labels, config['dropout'], bert_model=bert_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMZVmgxHFjng"
      },
      "source": [
        "####Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0mB0mhUYdCG"
      },
      "outputs": [],
      "source": [
        "def build_dataset(tokenizer_max_len, train, valid):\n",
        "    train_dataset = LiarDataset(list(train[TEXT]), train[range(n_labels)].values.tolist(), tokenizer, tokenizer_max_len)\n",
        "    valid_dataset = LiarDataset(list(valid[TEXT]), valid[range(n_labels)].values.tolist(), tokenizer, tokenizer_max_len)\n",
        "\n",
        "    return train_dataset, valid_dataset\n",
        "\n",
        "def build_dataloader(train_dataset, valid_dataset, batch_size):\n",
        "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "    return train_data_loader, valid_data_loader\n",
        "\n",
        "def loss_function (outputs, labels):\n",
        "    #return nn.BCELoss()(outputs, labels.float()) # https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html\n",
        "    return nn.MultiLabelSoftMarginLoss()(outputs, labels.float()) # https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html\n",
        "\n",
        "def log_metrics(preds, labels):\n",
        "    preds = torch.stack(preds)\n",
        "    preds = preds.cpu().detach().numpy()\n",
        "    labels = torch.stack(labels)\n",
        "    labels = labels.cpu().detach().numpy()\n",
        "\n",
        "    labels = labels.argmax(axis=1)\n",
        "    pred_f1 = preds.argmax(axis = 1)\n",
        "\n",
        "    return {\"precision\": metrics.precision_score(labels, pred_f1),\n",
        "            \"recall\": metrics.recall_score(labels, pred_f1),\n",
        "            \"f1\": metrics.f1_score(labels, pred_f1)}\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    for d in tqdm(data_loader):\n",
        "        ids = d[\"ids\"].to(device, dtype=torch.long)\n",
        "        mask = d[\"mask\"].to(device, dtype=torch.long)\n",
        "        targets = d[\"labels\"].to(device, dtype=torch.long)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(ids=ids, mask=mask)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    return train_loss\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader)):\n",
        "            ids = d[\"ids\"].to(device, dtype=torch.long)\n",
        "            mask = d[\"mask\"].to(device, dtype=torch.long)\n",
        "            targets = d[\"labels\"].to(device, dtype=torch.long)\n",
        "\n",
        "            outputs = model(ids=ids, mask=mask)\n",
        "            fin_targets.extend(targets)\n",
        "            fin_outputs.extend(torch.sigmoid(outputs))\n",
        "    return fin_outputs, fin_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fObqx5emNSEZ",
        "outputId": "b521cf69-5bca-409b-9c17-9e8c49d7c9e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "bert_model = transformers.AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def trainer(config):\n",
        "        train_dataset, valid_dataset = build_dataset(config['tokenizer_max_len'],train,valid)\n",
        "        train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config['batch_size'])\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = Classifier(n_labels, config['dropout'], bert_model=bert_model)\n",
        "        model.to(device)\n",
        "\n",
        "        optimizer = AdamW(model.parameters(), lr = config['learning_rate'])\n",
        "        n_epochs = config['epochs']\n",
        "\n",
        "        for epoch in tqdm(range(n_epochs),desc='Loading:',disable=True):\n",
        "\n",
        "            train_loss = train_fn(train_data_loader, model, optimizer, device) #, scheduler)\n",
        "            preds, labels = eval_fn(valid_data_loader, model, device)\n",
        "\n",
        "            res_metrics = log_metrics(preds, labels)\n",
        "            precision = res_metrics[\"precision\"]\n",
        "            recall = res_metrics[\"recall\"]\n",
        "            f1 = res_metrics[\"f1\"]\n",
        "            avg_train_loss = train_loss / len(train_data_loader)\n",
        "\n",
        "            print(\"\\nF1-score: \", f1, \"Average Train loss: \", avg_train_loss)\n",
        "\n",
        "            print(\"\\n--------- Epoch {} finished ---------\\n\".format(epoch))\n",
        "\n",
        "\n",
        "            if epoch == config[\"epochs\"]-1:\n",
        "                torch.save(model.state_dict(),\n",
        "                           f'{path}-epoch_{epoch}-lr_{config[\"learning_rate\"]}-batch_{config[\"batch_size\"]}-drop_{config[\"dropout\"]}-maxlen_{config[\"tokenizer_max_len\"]}-f1_{round(f1, 5)}-{pst_now.strftime(\"%Y-%m-%d_%H-%M-%S\")}.pt' )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4UnH3s0FL_m",
        "outputId": "a4c9f432-adc4-469e-f1c4-cdf4f9c79330"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 134/134 [01:30<00:00,  1.48it/s]\n",
            "17it [00:03,  4.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1-score:  0.8816326530612245 Average Train loss:  0.4967743122755592\n",
            "\n",
            "--------- Epoch 0 finished ---------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 134/134 [01:29<00:00,  1.49it/s]\n",
            "17it [00:03,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1-score:  0.8816326530612245 Average Train loss:  0.4877442367263694\n",
            "\n",
            "--------- Epoch 1 finished ---------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 134/134 [01:30<00:00,  1.49it/s]\n",
            "17it [00:03,  4.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1-score:  0.8816326530612245 Average Train loss:  0.48588270838580916\n",
            "\n",
            "--------- Epoch 2 finished ---------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 134/134 [01:29<00:00,  1.49it/s]\n",
            "17it [00:03,  4.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1-score:  0.8816326530612245 Average Train loss:  0.4928605260688867\n",
            "\n",
            "--------- Epoch 3 finished ---------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 134/134 [01:29<00:00,  1.49it/s]\n",
            "17it [00:03,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1-score:  0.8816326530612245 Average Train loss:  0.4881835111708783\n",
            "\n",
            "--------- Epoch 4 finished ---------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkcrRj2UhgLL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
